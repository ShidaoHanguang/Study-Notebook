# 机器学习

## 一、基础概念

通过**特征**形成**专家系统**，利用**算法**对**实例**进行**分类、回归**等操作的方式。



###### 常用算法罗列

|    监督学习的用途    |                          |
| :------------------: | :----------------------: |
|     *k*-近邻算法     |         线性回归         |
|    朴素贝叶斯算法    |     局部加权线性回归     |
|      支持向量机      |       *Ridge* 回归       |
|        决策树        | *Lasso* 最小回归系数估计 |
| **无监督学习的用途** |                          |
|       *k*-均值       |       最大期望算法       |
|       *DBSCAN*       |     *Parzen* 窗设计      |

## 二、常用算法

### 1. K-近邻算法

​	存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据与所属分类的对应关系。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。一般来说，我们只选择样本数据集中前*k*个最相似的数据，这就是*k*-近邻算法中*k*的出处，通常*k*是不大于20的整数。最后，选择*k*个最相似数据中出现次数最多的分类，作为新数据的分类。

#### 简单距离算法构建

```python
def classify0(inX, dataSet, labels, k):
    # 获取数据集大小
    dataSetSize = dataSet.shape[0]
    # np.tile用于沿指定方向复制数组。它的语法是 np.tile(array, reps)，其中 
    # array 是要复制的数组，reps 是指定沿每个轴重复的次数的元组。
    diffMat = np.tile(inX, (dataSetSize,1)) - dataSet
    sqDiffMat = diffMat ** 2
    # 这里实现的就是计算输入点距各数据集中点的距离
    sqDistance = sqDiffMat.sum(axis = 1)
    distances = sqDistance ** 0.5
    # 返回数组中元素排序后的索引
    sortedDistIndicies = distances.argsort()
    classCount = {}
    # 获取前k种可能的情况
    for i in range(k):
        voteIlabel = labels[sortedDistIndicies[i]]
        classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1
    # 根据情况对应次数排序
    sortedClassCount = sorted(classCount.items(),key = operator.itemgetter(1),reverse = True)
    return sortedClassCount[0][0]
```

###### 

#### 从文本中获取数据及分类

##### matplotlib功能展示

```python
ax.scatter(datingDataMat[:,1], datingDataMat[:,2], 15.0 * np.array(datingLabels), 15.0 * np.array(datingLabels))
```

这行代码使用 matplotlib的 `scatter` 函数绘制散点图。根据提供的参数，它会将 `datingDataMat` 矩阵的第二列作为 x 坐标，第三列作为 y 坐标，并根据 `datingLabels` 数组中的值来确定散点的颜色和大小。

具体解释如下：

- `datingDataMat[:,1]` 表示取 `datingDataMat` 矩阵的所有行的第二列作为 x 坐标。
- `datingDataMat[:,2]` 表示取 `datingDataMat` 矩阵的所有行的第三列作为 y 坐标。
- `15.0 * np.array(datingLabels)` 表示将 `datingLabels` 数组中的每个元素乘以 15.0，生成一个新的数组，用于设置散点的大小。
- `ax.scatter()` 函数的前两个参数是 x 和 y 坐标，第三个参数是每个散点的大小，第四个参数是每个散点的颜色。

##### 

##### 标准化

```python
def autoNorm(dataSet):
    # dataSet.min(0)表示从列中取最小值
    minVals = dataSet.min(0)
    maxVals = dataSet.max(0)
    ranges = maxVals - minVals
    normDataSet = np.zeros(np.shape(dataSet))
    m = dataSet.shape[0]
    normDataSet = dataSet - np.tile(minVals, (m,1))
    normDataSet = normDataSet/np.tile(ranges, (m,1))   
    return normDataSet, ranges, minVals
```



##### 整体检测算法

```python
def datingClassTest(filepath,hoRatio,k):
    # 获取数据集
    datingDataMat,datingLabels = file2matrix(filepath)       #load data setfrom file
    normMat, ranges, minVals = autoNorm(datingDataMat)
    # 整个数据集长度
    m = normMat.shape[0]
    # 设定检测数据集范围
    numTestVecs = int(m*hoRatio)
    errorCount = 0.0
    for i in range(numTestVecs):
        # 进行kNN算法检测
        classifierResult = classify0(normMat[i,:],normMat[numTestVecs:m,:],datingLabels[numTestVecs:m],k)
        print ("the classifier came back with: {}, the real answer is: {}".format(classifierResult, datingLabels[i]))
        # 统计错误次数
        if classifierResult != datingLabels[i]: 
            errorCount += 1.0
    print ("the total error rate is: {}" .format(errorCount/float(numTestVecs)))
    print (errorCount)
```



##### 简单的预测算法

```python
def classifyPerson():
    resultList = ['not at all', 'in small doses', 'in large doses']
    percentTats = float(input("请输入用于玩游戏的时间比列："))
    ffMiles = float(input("请输入每年获取的飞行常客里程数："))
    iceCream = float(input("请输入每年冰淇淋的消耗量："))
    datingDataMat,datingLabels = file2matrix('datingTestSet2.txt')
    normMat, ranges, minVals = autoNorm(datingDataMat)
    inArr = np.array([ffMiles, percentTats, iceCream])
    classifierResult = classify0((inArr - minVals) / ranges, normMat, datingLabels, 3)
    print("你可能会喜欢这个人：{}".format(resultList[classifierResult - 1]))
```



#### 从图像中获取数据

```python
def handwritingClassTest():
    hwLabels = []
    # 读取训练数据文件夹中的文件
    trainingFileList = os.listdir('trainingDigits')           
    m = len(trainingFileList)
    trainingMat = np.zeros((m,1024))
    # 读取为矩阵
    for i in range(m):
        fileNameStr = trainingFileList[i]
        fileStr = fileNameStr.split('.')[0]     
        classNumStr = int(fileStr.split('_')[0])
        hwLabels.append(classNumStr)
        trainingMat[i,:] = img2vector('trainingDigits/' + fileNameStr)
    testFileList = os.listdir('testDigits')        
    errorCount = 0.0
    # 读取测试数据文件夹中的文件
    mTest = len(testFileList)
    errorlist = {}
    for i in range(mTest):
        fileNameStr = testFileList[i]
        fileStr = fileNameStr.split('.')[0]     
        classNumStr = int(fileStr.split('_')[0])
        vectorUnderTest = img2vector('testDigits/' + fileNameStr)
        classifierResult = classify0(vectorUnderTest, trainingMat, hwLabels, 3)
        print ("the classifier came back with: {}, the real answer is: {}".format(classifierResult, classNumStr))
        if classifierResult != classNumStr : 
            errorCount += 1.0
            errorlist[fileNameStr] = classifierResult
    print("the total number of errors is: {}".format(errorCount))
    print("the total error rate is: {}".format(errorCount/float(mTest)))
    return errorlist
```

